"""
Aplikacja Streamlit do analizy s≈Ç√≥w kluczowych.
"""
import streamlit as st
import pandas as pd
import numpy as np
# import matplotlib.pyplot as plt # Nieu≈ºywane
# import plotly.express as px # Importowane w visualizer
# import plotly.graph_objects as go # Importowane w visualizer
import os
import sys
import time
import requests # Do komunikacji z API OpenRouter
import logging  # Do logowania
from typing import List, Dict, Any, Optional, Tuple
import umap # <<<< DODANY IMPORT DLA UMAP >>>>

# Dodaj katalog projektu do ≈õcie≈ºki
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Importy z projektu
from utils.data_loader import load_and_prepare_data, save_analysis, load_analysis
from models.embeddings import EmbeddingGenerator
from models.clustering import KeywordClusterer
from models.analyzer import KeywordAnalyzer
from utils.visualizer import KeywordVisualizer
from config.config import (
    DATA_DIR, OUTPUT_DIR,
    # Za≈Ç√≥≈ºmy, ≈ºe te parametry istniejƒÖ w config.py dla wizualizacji UMAP 3D
    # Je≈õli nie, mo≈ºesz je zdefiniowaƒá na sztywno poni≈ºej lub dodaƒá do config.py
    UMAP_N_NEIGHBORS as UMAP_VIS_N_NEIGHBORS_DEFAULT, 
    UMAP_MIN_DIST as UMAP_VIS_MIN_DIST_DEFAULT,
    # Sta≈Çe OpenRouter z config.py
    OPENROUTER_API_BASE,
    OPENROUTER_MODELS_ENDPOINT,
    OPENROUTER_CHAT_ENDPOINT,
    GEMINI_MODEL as DEFAULT_GEMINI_MODEL
)

# Inicjalizacja loggera
logger = logging.getLogger(__name__)

# Konfiguracja strony
st.set_page_config(
    page_title="Analizator S≈Ç√≥w Kluczowych",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Funkcje Pomocnicze ---
@st.cache_data(ttl=3600) # Cache'uj listƒô modeli przez godzinƒô
def fetch_openrouter_models(api_key: str) -> List[str]:
    """Pobiera listƒô dostƒôpnych modeli z API OpenRouter."""
    if not api_key:
        # Nie wy≈õwietlamy b≈Çƒôdu tutaj, bo mo≈ºe to byƒá celowe (u≈ºycie .env)
        # logger.warning("Pr√≥ba pobrania modeli OpenRouter bez klucza API.")
        return []
    
    headers = {"Authorization": f"Bearer {api_key}"}
    models_url = OPENROUTER_API_BASE + OPENROUTER_MODELS_ENDPOINT
    model_ids = []
    try:
        response = requests.get(models_url, headers=headers, timeout=15) # Dodano timeout
        response.raise_for_status() 
        models_data = response.json().get("data", [])
        model_ids = sorted([model.get("id") for model in models_data if model.get("id")])
        logger.info(f"Pobrano {len(model_ids)} modeli z OpenRouter.")
    except requests.exceptions.RequestException as e:
        logger.error(f"B≈ÇƒÖd podczas pobierania modeli z OpenRouter: {e}")
        st.error(f"B≈ÇƒÖd po≈ÇƒÖczenia z OpenRouter: {e}. Sprawd≈∫ klucz API i po≈ÇƒÖczenie.")
    except Exception as e:
        logger.error(f"Nieoczekiwany b≈ÇƒÖd podczas przetwarzania modeli OpenRouter: {e}")
        st.error(f"WystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd: {e}")
    return model_ids

# Tytu≈Ç aplikacji
st.title("Analizator S≈Ç√≥w Kluczowych")
st.markdown("**Narzƒôdzie do klastrowania i analizy s≈Ç√≥w kluczowych z wykorzystaniem AI**")

# Panel boczny
st.sidebar.header("Ustawienia")

st.sidebar.subheader("Import/Eksport analizy")
if st.sidebar.button("üíæ Zapisz analizƒô", type="secondary"):
    if 'clustered_df' in st.session_state:
        analysis_data = {
            'keywords_df': st.session_state.get('keywords_df'),
            'stats': st.session_state.get('stats'),
            'df_with_embeddings': st.session_state.get('df_with_embeddings'),
            'reduced_embeddings': st.session_state.get('reduced_embeddings'), 
            'clustered_df': st.session_state.get('clustered_df'),
            'cluster_names': st.session_state.get('cluster_names'),
            'cluster_analyses': st.session_state.get('cluster_analyses'),
            'plots': st.session_state.get('plots'),
            'intent_plot': st.session_state.get('intent_plot'),
            'cluster_map': st.session_state.get('cluster_map'),
            # <<<< DODAJEMY NOWE ELEMENTY DO ZAPISU DLA MAPY 3D >>>>
            'cluster_map_3d': st.session_state.get('cluster_map_3d'),
            'original_embeddings_for_vis': st.session_state.get('original_embeddings_for_vis'),
            'reduced_embeddings_3d_for_vis': st.session_state.get('reduced_embeddings_3d_for_vis')
        }
        save_path = save_analysis(analysis_data)
        st.sidebar.success(f"Analiza zapisana: {os.path.basename(save_path)}")
    else:
        st.sidebar.error("Brak danych do zapisania. Wykonaj analizƒô przed zapisaniem.")

import_file = st.sidebar.file_uploader("Wczytaj zapisanƒÖ analizƒô (.pkl)", type=["pkl"], key="import_analysis_file")
if import_file and 'file_already_imported' not in st.session_state:
    try:
        temp_path = os.path.join(DATA_DIR, import_file.name)
        with open(temp_path, "wb") as f: f.write(import_file.getbuffer())
        loaded_data = load_analysis(temp_path)
        for key, value in loaded_data.items(): st.session_state[key] = value
        st.session_state.analysis_completed = True
        st.session_state.file_imported = True
        st.session_state.imported_file_name = import_file.name
        st.session_state.file_already_imported = True
        st.sidebar.success(f"Analiza wczytana: {import_file.name}")
        st.rerun()
    except Exception as e:
        st.sidebar.error(f"B≈ÇƒÖd podczas wczytywania analizy: {e}")
        if 'file_already_imported' in st.session_state: del st.session_state.file_already_imported

st.sidebar.markdown("---")

# <<<< POCZƒÑTEK NOWEJ SEKCJI: Wyb√≥r Modelu AI i Klucze API >>>>
st.sidebar.markdown("---") # Dodatkowe oddzielenie
st.sidebar.subheader("Konfiguracja Modelu AI")

# Inicjalizacja stanu sesji
if 'ai_provider' not in st.session_state: st.session_state.ai_provider = "Gemini"
if 'selected_openrouter_model' not in st.session_state: st.session_state.selected_openrouter_model = None
if 'openrouter_models_list' not in st.session_state: st.session_state.openrouter_models_list = []
# Przechowuj klucze w session_state, aby nie znika≈Çy po interakcjach
if 'gemini_key_ui' not in st.session_state: st.session_state.gemini_key_ui = ""
if 'openrouter_key_ui' not in st.session_state: st.session_state.openrouter_key_ui = ""
if 'jina_key_ui' not in st.session_state: st.session_state.jina_key_ui = ""

# Wyb√≥r dostawcy
ai_provider = st.sidebar.radio(
    "Wybierz dostawcƒô modelu jƒôzykowego:",
    ("Gemini", "OpenRouter"),
    key='ai_provider_radio',
    index=["Gemini", "OpenRouter"].index(st.session_state.ai_provider), # Ustaw domy≈õlny
    # Nie potrzeba on_change, bo stan jest aktualizowany przez sam widget
)
st.session_state.ai_provider = ai_provider # Zapisz wyb√≥r w stanie sesji

st.sidebar.subheader("Klucze API")
st.sidebar.caption("Wprowad≈∫ klucze API. Je≈õli pozostawisz puste, aplikacja spr√≥buje u≈ºyƒá kluczy z pliku .env (je≈õli dzia≈Çasz lokalnie).")

# Pola na klucze API - przypisanie do session_state
st.session_state.gemini_key_ui = st.sidebar.text_input(
    "Klucz API Google Gemini:", 
    type="password", 
    value=st.session_state.gemini_key_ui, # Odczytaj warto≈õƒá ze stanu
    help="Potrzebny, je≈õli jako dostawcƒô wybrano Gemini."
)
st.session_state.openrouter_key_ui = st.sidebar.text_input(
    "Klucz API OpenRouter:", 
    type="password", 
    value=st.session_state.openrouter_key_ui, # Odczytaj warto≈õƒá ze stanu
    help="Potrzebny, je≈õli jako dostawcƒô wybrano OpenRouter."
)
st.session_state.jina_key_ui = st.sidebar.text_input(
    "Klucz API JINA:", 
    type="password", 
    value=st.session_state.jina_key_ui, # Odczytaj warto≈õƒá ze stanu
    help="Potrzebny do generowania embedding√≥w."
)

# Sekcja dla OpenRouter - ≈Çadowanie i wyb√≥r modelu
if st.session_state.ai_provider == "OpenRouter":
    st.sidebar.markdown("### Konfiguracja OpenRouter")
    
    # Przycisk do pobrania modeli
    if st.sidebar.button("Pobierz/Od≈õwie≈º modele OpenRouter"):
        or_key = st.session_state.openrouter_key_ui.strip()
        if or_key:
            # Wywo≈Çaj funkcjƒô z cache - je≈õli klucz siƒô nie zmieni≈Ç, zwr√≥ci z cache
            with st.spinner("Pobieranie listy modeli..."):
                models = fetch_openrouter_models(or_key) 
            if models:
                st.session_state.openrouter_models_list = models
                # Je≈õli poprzednio wybrany model nie jest ju≈º na li≈õcie lub nic nie wybrano,
                # ustaw domy≈õlny (np. pierwszy z listy) lub zostaw None
                if st.session_state.selected_openrouter_model not in models:
                    st.session_state.selected_openrouter_model = models[0] if models else None
                st.sidebar.success(f"Pobrano/od≈õwie≈ºono {len(models)} modeli.")
                st.rerun() # Prze≈Çaduj, aby zaktualizowaƒá selectbox
            else:
                st.session_state.openrouter_models_list = [] 
                st.session_state.selected_openrouter_model = None # Resetuj wyb√≥r
        else:
            st.sidebar.warning("Wprowad≈∫ klucz API OpenRouter, aby pobraƒá listƒô modeli.")

    # Selectbox do wyboru modelu OpenRouter
    # Upewnij siƒô, ≈ºe indeks jest poprawny
    current_model_index = 0
    if st.session_state.selected_openrouter_model and st.session_state.openrouter_models_list:
        try:
            current_model_index = st.session_state.openrouter_models_list.index(st.session_state.selected_openrouter_model)
        except ValueError:
            current_model_index = 0 # Je≈õli poprzedni wyb√≥r zniknƒÖ≈Ç, wybierz pierwszy

    selected_model = st.sidebar.selectbox(
        "Wybierz model OpenRouter:",
        st.session_state.openrouter_models_list,
        index=current_model_index,
        key='selected_model_selectbox_widget', # U≈ºyj innego klucza dla widgetu
        disabled=not st.session_state.openrouter_models_list 
    )
    # Zapisz wyb√≥r do stanu sesji tylko je≈õli jest r√≥≈ºny
    if selected_model != st.session_state.selected_openrouter_model:
         st.session_state.selected_openrouter_model = selected_model
         # Nie ma potrzeby rerun tutaj, selectbox sam siƒô aktualizuje
# <<<< KONIEC NOWEJ SEKCJI >>>>

st.sidebar.markdown("---")
st.sidebar.subheader("Nowa analiza")

def process_keywords(file_path):
    progress_col, status_col = st.columns([3, 2])
    overall_progress_bar = progress_col.progress(0)
    overall_status = progress_col.empty()
    step_progress_bar = progress_col.progress(0)
    step_status = progress_col.empty()
    current_step_container = status_col.empty()
    
    def update_progress(overall_progress, step_progress, overall_text, step_text, step_name):
        overall_progress_bar.progress(overall_progress)
        overall_status.text(overall_text)
        step_progress_bar.progress(step_progress)
        step_status.text(step_text)
        current_step_container.markdown(f"### Obecny krok: {step_name}")
    
    update_progress(0.0, 0.0, "Inicjalizacja...", "Wczytywanie pliku...", "Przetwarzanie danych")
    df, stats = load_and_prepare_data(file_path)
    st.session_state.keywords_df = df
    st.session_state.stats = stats
    update_progress(0.05, 1.0, "Przetwarzanie danych zako≈Ñczone", "Plik wczytany", "Przetwarzanie danych")
    
    # Krok 2: Generuj embeddingi (10% - 30%)
    # <<<< ZMIANA: Inicjalizacja z kluczem JINA z session_state >>>>
    current_jina_api_key = st.session_state.jina_key_ui.strip() if st.session_state.jina_key_ui and st.session_state.jina_key_ui.strip() else None
    try:
        embedding_generator = EmbeddingGenerator(api_key=current_jina_api_key)
        # Sprawdzanie czy klient powsta≈Ç (zak≈ÇadajƒÖc, ≈ºe konstruktor ustawia self.client na None przy b≈Çƒôdzie)
        if hasattr(embedding_generator, 'client') and embedding_generator.client is None:
            # Spr√≥bujmy za≈Çadowaƒá z config jako fallback, je≈õli nie podano w UI
            from config.config import JINA_API_KEY as CONFIG_JINA_API_KEY
            if CONFIG_JINA_API_KEY:
                embedding_generator = EmbeddingGenerator(api_key=CONFIG_JINA_API_KEY)
                if hasattr(embedding_generator, 'client') and embedding_generator.client is None:
                    st.error("Klucz API JINA z pliku .env r√≥wnie≈º jest nieprawid≈Çowy.")
                    return
            else:
                 st.error("Brak klucza API dla JINA. Podaj go w panelu bocznym lub ustaw w .env.")
                 return
    except Exception as e: 
        st.error(f"B≈ÇƒÖd inicjalizacji JINA: {e}")
        return
    # <<<< KONIEC ZMIANY >>>>
    
    def embedding_callback(progress, status):
        update_progress(0.05 + 0.20 * progress, progress, "Generowanie embeding√≥w...", status, "Generowanie embeding√≥w")
    df_with_embeddings = embedding_generator.process_keywords_dataframe(df, progress_callback=embedding_callback)
    st.session_state.df_with_embeddings = df_with_embeddings
    
    # <<<< PRZECHOWUJEMY ORYGINALNE EMBEDDINGI DLA WIZUALIZACJI 3D >>>>
    if 'embedding' in df_with_embeddings.columns:
        st.session_state.original_embeddings_for_vis = np.array(df_with_embeddings['embedding'].tolist())
    else:
        st.warning("Brak kolumny 'embedding' w danych. Mapa 3D mo≈ºe nie zostaƒá wygenerowana.")
        st.session_state.original_embeddings_for_vis = None

    clusterer = KeywordClusterer()
    def clustering_callback(progress, status):
        update_progress(0.25 + 0.20 * progress, progress, "Klastrowanie s≈Ç√≥w kluczowych...", status, "Klastrowanie")
    clustered_df = clusterer.process_keywords_dataframe(df_with_embeddings, progress_callback=clustering_callback)
    st.session_state.reduced_embeddings = clusterer.reduced_embeddings 
    st.session_state.clustered_df = clustered_df
    
    # Krok 4: Nazwij klastry (50% - 65%)
    # <<<< ZMIANA: Inicjalizacja Analizatora z odpowiednim kluczem i modelem >>>>
    llm_api_key_to_use = None
    llm_model_name_to_use = None
    llm_provider = st.session_state.ai_provider # Pobierz wybranego dostawcƒô

    if llm_provider == "Gemini":
        # Sprawd≈∫ klucz z UI, potem z config/.env
        key_from_ui = st.session_state.gemini_key_ui.strip()
        if key_from_ui:
            llm_api_key_to_use = key_from_ui
        else:
            from config.config import GEMINI_API_KEY as CONFIG_GEMINI_API_KEY
            if CONFIG_GEMINI_API_KEY:
                llm_api_key_to_use = CONFIG_GEMINI_API_KEY
            else:
                 st.error("Wybrano Gemini, ale nie podano klucza API ani nie znaleziono go w .env.")
                 return # Zako≈Ñcz, je≈õli nie ma klucza

        llm_model_name_to_use = DEFAULT_GEMINI_MODEL # U≈ºyj domy≈õlnego Gemini z config
    
    elif llm_provider == "OpenRouter":
        # Sprawd≈∫ klucz z UI, potem z config/.env
        key_from_ui = st.session_state.openrouter_key_ui.strip()
        if key_from_ui:
            llm_api_key_to_use = key_from_ui
        else:
            from config.config import OPENROUTER_API_KEY as CONFIG_OPENROUTER_API_KEY
            if CONFIG_OPENROUTER_API_KEY:
                llm_api_key_to_use = CONFIG_OPENROUTER_API_KEY
            else:
                 st.error("Wybrano OpenRouter, ale nie podano klucza API ani nie znaleziono go w .env.")
                 return # Zako≈Ñcz, je≈õli nie ma klucza
        
        # Pobierz wybrany model ze stanu sesji
        if 'selected_openrouter_model' not in st.session_state:
            st.session_state.selected_openrouter_model = None  # Inicjalizacja, je≈õli nie istnieje
        llm_model_name_to_use = st.session_state.selected_openrouter_model 
        if not llm_model_name_to_use:
            st.error("Wybrano OpenRouter, ale nie wybrano modelu. Pobierz listƒô modeli i wybierz jeden.")
            return
    
    # Inicjalizuj KeywordAnalyzer z wybranymi parametrami
    try:
        analyzer = KeywordAnalyzer(
            api_key=llm_api_key_to_use, 
            model_name=llm_model_name_to_use,
            provider=llm_provider # Przeka≈º informacjƒô o dostawcy
        )
    except ValueError as e: 
        st.error(f"B≈ÇƒÖd inicjalizacji modelu AI: {e}")
        return
    except Exception as e:
        st.error(f"Nieoczekiwany b≈ÇƒÖd inicjalizacji modelu AI: {e}")
        return
    # <<<< KONIEC ZMIANY >>>>
    
    def naming_callback(progress, status):
        update_progress(0.45 + 0.15 * progress, progress, "Nazywanie klastr√≥w...", status, "Nazywanie klastr√≥w")
    cluster_names = analyzer.name_clusters(clustered_df, progress_callback=naming_callback)
    st.session_state.cluster_names = cluster_names
    
    def analysis_callback(progress, status):
        update_progress(0.60 + 0.18 * progress, progress, "Analizowanie klastr√≥w...", status, "Analiza klastr√≥w") # Zmieniono overall_progress
    cluster_analyses = analyzer.process_all_clusters(clustered_df, cluster_names, progress_callback=analysis_callback)
    st.session_state.cluster_analyses = cluster_analyses
    
    # <<<< GENEROWANIE EMBEDDING√ìW 3D DLA WIZUALIZACJI >>>>
    update_progress(0.78, 0.0, "Przygotowanie danych do wizualizacji 3D...", "Redukcja do 3D...", "Wizualizacja 3D")
    if st.session_state.get('original_embeddings_for_vis') is not None:
        try:
            umap_3d_visualizer = umap.UMAP(
                n_neighbors=UMAP_VIS_N_NEIGHBORS_DEFAULT, 
                n_components=3, 
                min_dist=UMAP_VIS_MIN_DIST_DEFAULT,    
                random_state=42,
                n_jobs=1 
            )
            reduced_embeddings_3d_for_vis = umap_3d_visualizer.fit_transform(st.session_state.original_embeddings_for_vis)
            st.session_state.reduced_embeddings_3d_for_vis = reduced_embeddings_3d_for_vis
            update_progress(0.80, 1.0, "Dane do wizualizacji 3D gotowe.", "Redukcja do 3D zako≈Ñczona.", "Wizualizacja 3D")
        except Exception as e:
            st.warning(f"Nie uda≈Ço siƒô wygenerowaƒá embedding√≥w 3D dla wizualizacji: {e}")
            st.session_state.reduced_embeddings_3d_for_vis = None
            update_progress(0.80, 1.0, "B≈ÇƒÖd w przygotowaniu danych 3D.", f"B≈ÇƒÖd: {e}", "Wizualizacja 3D")
    else:
        update_progress(0.80, 1.0, "Pominiƒôto przygotowanie danych 3D.", "Brak embedding√≥w.", "Wizualizacja 3D")
        st.session_state.reduced_embeddings_3d_for_vis = None


    update_progress(0.85, 0.0, "Tworzenie wizualizacji...", "Przygotowywanie wykres√≥w...", "Wizualizacja")
    visualizer = KeywordVisualizer()
    
    update_progress(0.88, 0.2, "Tworzenie wizualizacji...", "Wykres podsumowania klastr√≥w...", "Wizualizacja")
    plots = visualizer.plot_cluster_summary(cluster_analyses)
    st.session_state.plots = plots
    
    update_progress(0.91, 0.4, "Tworzenie wizualizacji...", "Wykres rozk≈Çadu intencji...", "Wizualizacja")
    intent_plot = visualizer.plot_intent_distribution(stats)
    st.session_state.intent_plot = intent_plot
    
    update_progress(0.94, 0.6, "Tworzenie wizualizacji...", "Mapa klastr√≥w 2D...", "Wizualizacja")
    cluster_map_2d = visualizer.plot_cluster_map(clustered_df, cluster_names, st.session_state.reduced_embeddings)
    st.session_state.cluster_map = cluster_map_2d
    
    # <<<< GENEROWANIE MAPY 3D >>>>
    update_progress(0.97, 0.8, "Tworzenie wizualizacji...", "Mapa klastr√≥w 3D...", "Wizualizacja")
    if st.session_state.get('reduced_embeddings_3d_for_vis') is not None:
        cluster_map_3d_fig = visualizer.plot_cluster_map_3d(
            st.session_state.clustered_df, 
            st.session_state.cluster_names, 
            st.session_state.reduced_embeddings_3d_for_vis
        )
        st.session_state.cluster_map_3d = cluster_map_3d_fig
    else:
        st.session_state.cluster_map_3d = None
        # st.warning("Pominiƒôto generowanie mapy klastr√≥w 3D z powodu braku embedding√≥w 3D.") # Ostrze≈ºenie ju≈º by≈Ço wy≈ºej

    update_progress(1.0, 1.0, "Analiza zako≈Ñczona", "Wszystkie wizualizacje gotowe", "Zako≈Ñczono")
    time.sleep(0.5)
    st.success("Analiza zako≈Ñczona!")
    progress_col.empty(); status_col.empty()

upload_file = st.sidebar.file_uploader("Wczytaj plik CSV/Excel z Ahrefs", type=["csv", "xlsx", "xls"])
if upload_file:
    file_path = os.path.join(DATA_DIR, upload_file.name)
    with open(file_path, "wb") as f: f.write(upload_file.getbuffer())
    st.session_state.file_uploaded = True
    st.session_state.file_path = file_path
    st.session_state.file_name = upload_file.name
    st.sidebar.success(f"Plik wczytany: {upload_file.name}")
    
    if st.sidebar.button("üöÄ Uruchom analizƒô", type="primary"):
        keys_to_clear = ['clustered_df', 'cluster_analyses', 'plots', 'intent_plot', 'cluster_map', 
                 'keywords_df', 'stats', 'df_with_embeddings', 'reduced_embeddings', 
                 'cluster_names', 
                 'cluster_map_3d', 'original_embeddings_for_vis', 'reduced_embeddings_3d_for_vis',
                 'analysis_completed', 'file_imported'
                 # NIE czy≈õcimy zmiennych OpenRouter
                ]
        for key in keys_to_clear:
            if key in st.session_state: del st.session_state[key]
        if 'file_already_imported' in st.session_state: del st.session_state.file_already_imported # Resetujemy flagƒô importu pliku
        process_keywords(file_path)
        st.session_state.analysis_completed = True
        
    if 'analysis_completed' in st.session_state and st.session_state.analysis_completed:
        if st.sidebar.button("‚Üª Analizuj ponownie"):
            keys_to_clear_rerun = ['clustered_df', 'cluster_analyses', 'plots', 'intent_plot', 'cluster_map', 
                       'keywords_df', 'stats', 'df_with_embeddings', 'reduced_embeddings', 
                       'cluster_names', 
                       'cluster_map_3d', 'original_embeddings_for_vis', 'reduced_embeddings_3d_for_vis',
                       'analysis_completed', 'file_imported'
                       # NIE czy≈õcimy zmiennych OpenRouter
                      ]
            for key in keys_to_clear_rerun:
                if key not in ['file_uploaded', 'file_path', 'file_name'] and key in st.session_state:
                    del st.session_state[key]
            if 'file_already_imported' in st.session_state: del st.session_state.file_already_imported # Resetujemy flagƒô importu pliku
            process_keywords(file_path)
            st.session_state.analysis_completed = True


if 'clustered_df' in st.session_state:
    st.header("PrzeglƒÖd danych")
    col1, col2, col3 = st.columns(3)
    with col1: st.metric("Liczba s≈Ç√≥w kluczowych", st.session_state.stats.get('total_keywords',0))
    with col2: st.metric("≈ÅƒÖczny wolumen wyszukiwa≈Ñ", st.session_state.stats.get('total_volume',0))
    with col3: st.metric("≈örednia trudno≈õƒá (KD)", f"{st.session_state.stats.get('avg_difficulty',0.0):.2f}")
    
    st.header("Rozk≈Çad intencji wyszukiwania")
    if 'intent_plot' in st.session_state and st.session_state.intent_plot:
        st.plotly_chart(st.session_state.intent_plot, use_container_width=True)
    
    st.header("Mapa klastr√≥w s≈Ç√≥w kluczowych (2D)")
    if 'cluster_map' in st.session_state and st.session_state.cluster_map:
        st.plotly_chart(st.session_state.cluster_map, use_container_width=True)

    # <<<< NOWA SEKCJA: WY≈öWIETLANIE MAPY KLASTR√ìW 3D >>>>
    if 'cluster_map_3d' in st.session_state and st.session_state.cluster_map_3d is not None:
        st.header("Interaktywna Mapa Klastr√≥w S≈Ç√≥w Kluczowych (3D)")
        # U≈ºywamy st.container() z ustalonƒÖ wysoko≈õciƒÖ dla wykresu 3D, aby uniknƒÖƒá nadmiernego scrollowania
        with st.container():
            st.plotly_chart(st.session_state.cluster_map_3d, use_container_width=True, height=700) 
    elif st.session_state.get('analysis_completed'): 
        if not st.session_state.get('original_embeddings_for_vis'):
             st.warning("Nie mo≈ºna wygenerowaƒá mapy 3D: Brak oryginalnych embedding√≥w.")
        elif not st.session_state.get('reduced_embeddings_3d_for_vis') and st.session_state.get('original_embeddings_for_vis') is not None:
             st.warning("Nie uda≈Ço siƒô wygenerowaƒá mapy klastr√≥w 3D (prawdopodobnie b≈ÇƒÖd podczas redukcji wymiarowo≈õci).")
    # <<<< KONIEC NOWEJ SEKCJI >>>>

    st.header("Podsumowanie klastr√≥w")
    if 'plots' in st.session_state and st.session_state.plots:
        col1_sum, col2_sum = st.columns(2)
        with col1_sum:
            st.subheader("Wolumen wyszukiwa≈Ñ wed≈Çug klastr√≥w")
            st.plotly_chart(st.session_state.plots['volume'], use_container_width=True)
        with col2_sum:
            st.subheader("Liczba s≈Ç√≥w kluczowych wed≈Çug klastr√≥w")
            st.plotly_chart(st.session_state.plots['count'], use_container_width=True)
        st.subheader("Trudno≈õƒá vs. wolumen vs. liczba s≈Ç√≥w kluczowych")
        st.plotly_chart(st.session_state.plots['scatter'], use_container_width=True)
        st.subheader("Rozk≈Çad priorytet√≥w klastr√≥w")
        st.plotly_chart(st.session_state.plots['priority'], use_container_width=True)
    
    st.header("Szczeg√≥≈Çowa analiza klastr√≥w")
    if 'cluster_analyses' in st.session_state:
        for cluster_analysis in st.session_state.cluster_analyses:
            priority_color = "#66bb6a"
            if cluster_analysis.get('priority_level') == 'Wysoki': priority_color = "#ff7043"
            elif cluster_analysis.get('priority_level') == '≈öredni': priority_color = "#ffa726"
            
            st.markdown(f"""<h3 style="margin-bottom: 0px;">{cluster_analysis.get('cluster_name', 'Brak Nazwy')} <span style="color: {priority_color}; font-size: 0.8em;">[{cluster_analysis.get('priority_level', 'Nieznany')} priorytet]</span></h3>""", unsafe_allow_html=True)
            
            # Poprawiona kolejno≈õƒá wy≈õwietlania (zgodnie z Twoim screenem)
            col_m1, col_m2, col_m3, col_m4, col_m5 = st.columns(5) 
            with col_m1: st.metric("Liczba s≈Ç√≥w kluczowych", cluster_analysis.get('keywords_count', 0))
            with col_m2: st.metric("≈ÅƒÖczny wolumen", cluster_analysis.get('total_volume', 0))
            with col_m3: st.metric("≈örednia trudno≈õƒá", f"{cluster_analysis.get('avg_difficulty', 0.0):.2f}")
            with col_m4: st.metric("≈öredni CPC", f"${cluster_analysis.get('avg_cpc', 0.0):.2f}")
            with col_m5: st.metric("Wynik Priorytetu", f"{cluster_analysis.get('priority_score', 0.0):.2f}")

            st.markdown(f"**Uzasadnienie Priorytetu (ocena LLM):** {cluster_analysis.get('priority_justification', 'Brak uzasadnienia od modelu.')}")
            st.markdown("**Wnioski (Insights):**")
            st.write(cluster_analysis.get('insights', 'Brak wniosk√≥w.'))
            st.markdown("**Strategia Contentowa (Content Strategy):**")
            st.write(cluster_analysis.get('content_strategy', 'Brak strategii.'))
            
            with st.expander("Zobacz s≈Çowa kluczowe w tym klastrze"):
                cluster_id = cluster_analysis.get('cluster_id')
                if cluster_id is not None and 'clustered_df' in st.session_state:
                    cluster_keywords_df_exp = st.session_state.clustered_df[st.session_state.clustered_df['cluster'] == cluster_id]
                    if not cluster_keywords_df_exp.empty:
                        cluster_keywords_df_exp = cluster_keywords_df_exp.sort_values(by='volume', ascending=False) if 'volume' in cluster_keywords_df_exp else cluster_keywords_df_exp
                        intent_cols_exp = ['branded', 'local', 'navigational', 'informational', 'commercial', 'transactional']
                        available_intent_cols_exp = [col for col in intent_cols_exp if col in cluster_keywords_df_exp.columns]
                        display_cols_exp = ['keyword'] + [col for col in ['volume', 'difficulty', 'cpc'] if col in cluster_keywords_df_exp.columns]
                        if available_intent_cols_exp: display_cols_exp.extend(available_intent_cols_exp)
                        elif 'intent' in cluster_keywords_df_exp.columns: display_cols_exp.append('intent')
                        st.dataframe(cluster_keywords_df_exp[display_cols_exp])
                    else:
                        st.write("Brak s≈Ç√≥w kluczowych dla tego ID klastra.")
                else:
                    st.write("Nie mo≈ºna za≈Çadowaƒá s≈Ç√≥w kluczowych dla tego klastra.")
            st.markdown("---")
    
    st.header("Eksport wynik√≥w")
    if st.button("Eksportuj wszystkie s≈Çowa kluczowe z klastrami"):
        export_df_keywords = st.session_state.clustered_df.copy()
        export_df_keywords['cluster_name'] = export_df_keywords['cluster'].map(lambda c: st.session_state.cluster_names.get(c, f"Cluster {c}") if c != -1 else "Outliers")
        cols_to_drop_exp = [col for col in ['embedding'] if col in export_df_keywords.columns] 
        if 'intent_list' in export_df_keywords.columns and not export_df_keywords.empty and hasattr(export_df_keywords['intent_list'].iloc[0], '__iter__') and not isinstance(export_df_keywords['intent_list'].iloc[0], str): # Lepsze sprawdzenie listy
             export_df_keywords['intent_list'] = export_df_keywords['intent_list'].apply(lambda x: ', '.join(x) if hasattr(x, '__iter__') and not isinstance(x, str) else x)
        if cols_to_drop_exp: export_df_keywords = export_df_keywords.drop(columns=cols_to_drop_exp)
        export_path_keywords = os.path.join(OUTPUT_DIR, "keywords_with_clusters.csv")
        export_df_keywords.to_csv(export_path_keywords, index=False)
        st.markdown(f"Plik zosta≈Ç zapisany w: `{export_path_keywords}`")
    
    if st.button("Eksportuj analizƒô klastr√≥w"):
        export_df_analysis = pd.DataFrame(st.session_state.cluster_analyses)
        export_path_analysis = os.path.join(OUTPUT_DIR, "cluster_analysis.csv")
        export_df_analysis.to_csv(export_path_analysis, index=False)
        st.markdown(f"Plik zosta≈Ç zapisany w: `{export_path_analysis}`")
else:
    if 'file_imported' in st.session_state and st.session_state.file_imported:
        st.info(f"Wczytano zapisanƒÖ analizƒô: {st.session_state.imported_file_name}")
    else:
        st.info("Wczytaj plik CSV lub Excel z eksportu Ahrefs, aby rozpoczƒÖƒá analizƒô, lub zaimportuj zapisanƒÖ analizƒô.")
    st.markdown("""
    ### Oczekiwana struktura danych
    Plik powinien zawieraƒá co najmniej nastƒôpujƒÖce kolumny: `keyword`, `volume`, `difficulty` / `kd`, `intent`, `cpc`.
    Dodatkowo, dla rozk≈Çadu intencji, aplikacja obs≈Çuguje kolumny: `branded`, `local`, `navigational`, `informational`, `commercial`, `transactional`.
    Nazwy kolumn mogƒÖ nieznacznie siƒô r√≥≈ºniƒá - aplikacja spr√≥buje je zmapowaƒá automatycznie.
    """)